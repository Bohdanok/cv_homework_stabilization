{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ab42910-dabd-4f17-b552-d09fa0a616b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install numpy >> /dev/null\n",
    "# ! pip install pandas >> /dev/null\n",
    "# ! pip install opencv-python >> /dev/null\n",
    "# ! pip install scipy >> /dev/null\n",
    "# ! pip install torch >> /dev/null\n",
    "# ! pip install matplotlib >> /dev/null\n",
    "# ! pip install git+https://github.com/NVlabs/nvdiffrast >> /dev/null\n",
    "\n",
    "# %pip install pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cb91bcb-3ae4-4176-8b5b-3d9d3ea18717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7525dc9e",
   "metadata": {},
   "source": [
    "##### Download camera paramethers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6e2e827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/julfy/Documents/5th_term/cv/homework2\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "import yaml\n",
    "\n",
    "CAMERA = 0\n",
    "downloaded_params = None\n",
    "\n",
    "with open(\"camchain-calibration-equidistant4_camimu_dataset-calib-imu1.yaml\") as stream:\n",
    "    try:\n",
    "        downloaded_params = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        raise Exception(\"Hello!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff353fa-1760-4501-acd2-f2b5f4e5ba6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pin_hole_model = [743.4286936207343, 743.5545205462922, 618.7186883884866, 506.7275058699658]\n",
      "downloaded_params[f\"cam{CAMERA}\"][\"T_cam_imu\"] = [[-0.00596386151962109, -0.9999548067377452, 0.0074038393994521196, 0.05250867995679271], [-0.9999628101053462, 0.006009708608102947, 0.006185613038727172, 0.0077584026106338085], [-0.006229828408066805, -0.007366673911867888, -0.999953459593736, -0.04241050920541196], [0.0, 0.0, 0.0, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIR = \"./dataset-seq1/mav0/\" # replace with your sequence\n",
    "ORIGINAL_VIDEONAME = \"output_orig.mp4\"\n",
    "UNDISTORTED_VIDEONAME = \"output_undist.mp4\"\n",
    "RS_REMOVED_VIDEONAME = \"output_nors.mp4\"\n",
    "STABILIZED_VIDEONAME = \"output_stable_nors.mp4\"\n",
    "\n",
    "\n",
    "# camera params\n",
    "FPS = 20\n",
    "\n",
    "# camera intrinsics\n",
    "pin_hole_model = downloaded_params[f\"cam{CAMERA}\"][\"intrinsics\"]\n",
    "K = np.array([[pin_hole_model[0], 0, pin_hole_model[2]], \n",
    "              [0, pin_hole_model[1], pin_hole_model[3]],\n",
    "              [0, 0, 1]])\n",
    "\n",
    "# output camera intrinsics\n",
    "K_new = K.copy()\n",
    "\n",
    "# distortion params\n",
    "D = downloaded_params[f\"cam{CAMERA}\"][\"distortion_coeffs\"]\n",
    "\n",
    "# rotation from imu-to-camera\n",
    "R_cam_imu = downloaded_params[f\"cam{CAMERA}\"][\"T_cam_imu\"]\n",
    "\n",
    "# time delta between 2 sensor rows sensing \n",
    "dt_rs = 29.47 * 10 ** -6 # in seconds\n",
    "\n",
    "# frame dimensions\n",
    "W, H = 1280, 1024\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e614ca20-f87a-40dd-a8af-1ded4446154d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames in the video: 808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing frames to video: 100%|██████████| 808/808 [00:07<00:00, 103.29it/s]\n"
     ]
    }
   ],
   "source": [
    "def frames_to_video(frames, output_video, fps=20, isColor=False):\n",
    "    \"\"\"\n",
    "    Create a video from a list of frames.\n",
    "\n",
    "    :param frames: list of frames\n",
    "    :param output_video: output video file name (e.g., 'output.mp4')\n",
    "    :param fps: frames per second (default=20)\n",
    "    \"\"\"\n",
    "    if len(frames) == 0:\n",
    "        raise ValueError(\"No frames provided\")\n",
    "\n",
    "    # Use the first frame to get dimensions\n",
    "    height, width, *channels = frames[0].shape\n",
    "\n",
    "    # Define video writer (using mp4v codec)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(output_video, fourcc, fps, (width, height), isColor=isColor)\n",
    "\n",
    "    for frame in tqdm(frames, desc=\"Writing frames to video: \"):\n",
    "        video.write(frame)\n",
    "        \n",
    "\n",
    "frames_paths = sorted(glob.glob(os.path.join(INPUT_DIR, \"cam1/data/*.png\")))\n",
    "print(f\"Number of frames in the video: {len(frames_paths)}\")\n",
    "\n",
    "frames = [cv2.imread(frame_path, cv2.IMREAD_GRAYSCALE) for frame_path in frames_paths]\n",
    "frames_to_video(frames, ORIGINAL_VIDEONAME, FPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaa6809-4d6f-4ac8-978f-69c2478b8d4c",
   "metadata": {},
   "source": [
    "### Homework 2\n",
    "\n",
    "Given input video from camera with rolling shutter, implement and apply the following algorithms:\n",
    "\n",
    "    - radial distortion correction (use cv2.fisheye module)\n",
    "    - rolling shutter correction\n",
    "    - video stabilization\n",
    "\n",
    "Expected output of the homework:\n",
    "\n",
    "    - Jupyter notebook with working code that we can run in real-time\n",
    "    - plots of camera orientations in time for unstabilized and stabilized motion [plot individual x/y/z components in axis-angle representation]\n",
    "    - plots of input/output meshgrids for the video frame, where angular velocity has the biggest norm\n",
    "    - 4 videos stacked together with their frames side-by-side:\n",
    "        - original\n",
    "        - undistorted \n",
    "        - undistorted + rolling shutter corrected\n",
    "        - undistorted + rolling shutter corrected + stabilized\n",
    "\n",
    "Note:\n",
    "Dataset used in homework provides two sources of camera orientations: IMU (Gyro) measurements of angular velocity and Motion Capture direct measurements of orientation. You should use IMU (Gyro) measurements and implement angular velocity integration. You can use Motion Capture direct measurements of orientation to verify that your integration is implemented correctly.\n",
    "\n",
    "Rolling shutter correction algorithm is based on this paper: [Digital Video Stabilization and Rolling Shutter Correction using Gyroscopes](https://graphics.stanford.edu/papers/stabilization/).\n",
    "\n",
    "Dataset: [Rolling-Shutter Visual-Inertial Odometry Dataset](https://cvg.cit.tum.de/data/datasets/rolling-shutter-dataset)\n",
    "\n",
    "Calibrated camera params can be found [here](https://cdn3.vision.in.tum.de/rolling/calibration/camchain-calibration-equidistant4_camimu_dataset-calib-imu1.yaml)\n",
    "\n",
    "![Camera Set-up](https://cvg.cit.tum.de/_media/data/datasets/rolling-shutter-dataset/sensor_axes_rgb.jpg?w=800&tok=fa3d4a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b2d1b9",
   "metadata": {},
   "source": [
    "### Undistort the video using **cv2 fisheye module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2edb933-ded6-4167-9f1b-f0c38158d6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_hw2 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
